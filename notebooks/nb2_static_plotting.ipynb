{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Plotting and Basic Spatial Metrics\n",
    "\n",
    "**Tutor:** Tim Treis\n",
    "**Time:** 35 minutes\n",
    "\n",
    "---\n",
    "\n",
    "Now that we understand what a `SpatialData` object is and how to explore it interactively, let's learn how to create static, publication-quality plots and ask our first spatial question: \"Is this gene's expression pattern random, or is it spatially organized?\"\n",
    "\n",
    "**Goals:**\n",
    "1. Use `spatialdata-plot` to create layered, static images.\n",
    "2. Introduce a different technology: spot-based Visium data.\n",
    "3. Use `squidpy` to calculate and visualize a key spatial statistic, Moran's I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "First, let's import the libraries we'll need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cleaner output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata as sd\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to our data directory\n",
    "# Note: This path is relative to the repository's root directory\n",
    "_DATA_DIR_PATH = Path(\"../data/\")\n",
    "_VISIUM_PATH = _DATA_DIR_PATH / \"visium_glioblastoma_subset.zarr\"\n",
    "_XENIUM_PATH = _DATA_DIR_PATH / \"xenium_lung_cancer_subset.zarr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Plotting with `spatialdata-plot`\n",
    "\n",
    "For this section, we will use a dataset from a 10x Genomics Visium experiment. Unlike the high-resolution Xenium data from the previous notebook, Visium is a **spot-based** technology. It captures the whole transcriptome, but at the resolution of spots (~55Âµm) which may contain multiple cells.\n",
    "\n",
    "![Visium technology](../resources/visium_tech.png)\n",
    "\n",
    "Let's load our pre-processed Visium dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_visium = sd.read_zarr(_VISIUM_PATH)\n",
    "sdata_visium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command will fail because we haven't loaded spatialdata-plot yet\n",
    "\n",
    "sdata_visium.pl.render_images().pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `spatialdata-plot` library adds a `.pl` accessor to our `SpatialData` object. We can chain `render_*` functions to build up a plot layer by layer, similar to `ggplot`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .pl.render_images() and .pl.show()\n",
    "\n",
    "The [`.pl.render_images()`](https://spatialdata.scverse.org/projects/plot/en/latest/plotting.html#spatialdata_plot.pl.basic.PlotAccessor.render_images) function allows you to display the contaiend images. Under-the-hood optimizations allow you plot even extremely large images quickly. Furthermore, optional coordinate system transformations are respected.\n",
    "\n",
    "The [`.pl.show()`](https://spatialdata.scverse.org/projects/plot/en/latest/plotting.html#spatialdata_plot.pl.basic.PlotAccessor.show) function then actually renders the image, taking all previous function calls into account. They are evaluated in order and then stacked on top of each other. Only calling any of the `.pl.render_X` functions without `.pl.show` will not yield an image.\n",
    "\n",
    "Let's start by loading the library so the `.pl` acessor becomes available. We'll test it by rendering the histology image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata_plot as sdp\n",
    "\n",
    "sdata_visium.pl.render_images().pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the same image gets shown twice. That's because the Visium `SpatialData` object contains two coordinate systems: `downscaled_lowres` and `downscaled_hires`. Typically, the `global` coordinate system would contain the full-resolution image, but we've removed this here for faster downloading of the data.\n",
    "\n",
    "We can select one specific coordinate system in the `pl.show` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_visium.pl.render_images().pl.show(coordinate_systems=\"downscaled_hires\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further control the size of the figure by passing either the `figsize` parameter to the `pl.show` function or by directly passing an `ax` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_visium.pl.render_images().pl.show(coordinate_systems=\"downscaled_hires\", figsize=(2, 2))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "sdata_visium.pl.render_images().pl.show(coordinate_systems=\"downscaled_hires\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can adjust the title of the figure (default: name of the coordinate system) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_visium\n",
    "        .pl.render_images()\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            figsize=(2, 2),\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the actual [`.pl.render_images()`](https://spatialdata.scverse.org/projects/plot/en/latest/plotting.html#spatialdata_plot.pl.basic.PlotAccessor.render_images) call, we can also plot only selective channels. This becomes useful when, for example, plotting multi-channel IF data.(\n",
    "    sdata_visium\n",
    "        .pl.render_images()\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            figsize=(2, 2),\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_visium\n",
    "        .pl.render_images(channel=1)  # The green channel of the RGB image\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            figsize=(3, 2),\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .pl.render_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's overlay the circular Visium spots (`Shapes`) on top of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_visium\n",
    "        .pl.render_images()\n",
    "        .pl.render_shapes()  # First image, then shape, so that they're visible\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make them semi-transparent to see the tissue underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_visium\n",
    "        .pl.render_images()\n",
    "        .pl.render_shapes(fill_alpha=0.2)\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can of course also cover them by certain covariates such as the expression of certain genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_visium\n",
    "        .pl.render_images()\n",
    "        .pl.render_shapes(color=\"CST3\")\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of Visium data, we can furthermore specify the shape to be `visium_hex` which then fully covers the tissue and usually leads to a nicer visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_visium\n",
    "        .pl.render_images()\n",
    "        .pl.render_shapes(color=\"CST3\", shape=\"visium_hex\")\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass regular [`matplotlib.colors.Normalize`](https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.Normalize.html) and [`matplotlib.colors.Colormap`](https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.Colormap.html) objects to the function to further modify the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=400)\n",
    "cmap = matplotlib.cm.get_cmap(\"Reds\")\n",
    "\n",
    "(\n",
    "    sdata_visium\n",
    "        .pl.render_images()\n",
    "        .pl.render_shapes(color=\"CST3\", shape=\"visium_hex\", norm=norm, cmap=cmap)  # Alternatively, you can directly pass \"Reds\" to `cmap`\n",
    "        .pl.show(\n",
    "            coordinate_systems=\"downscaled_hires\",\n",
    "            title=\"Visium\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .pl.render_shapes() and .pl.render_labels()\n",
    "\n",
    "We will switch to the Xenium dataset to demonstrate the use of [`.pl.render_shapes`](https://spatialdata.scverse.org/projects/plot/en/latest/plotting.html#spatialdata_plot.pl.basic.PlotAccessor.render_shapes) and [`.pl.render_labels`](https://spatialdata.scverse.org/projects/plot/en/latest/plotting.html#spatialdata_plot.pl.basic.PlotAccessor.render_labels). With it we can, for example, plot individual cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium = sd.read_zarr(_XENIUM_PATH)\n",
    "\n",
    "# Let's subset the image to a smaller crop of it so we can better see the changes we're making.\n",
    "sdata_xenium_subset = sdata_xenium.query.bounding_box(\n",
    "    axes=[\"x\", \"y\"],\n",
    "    min_coordinate=[31_000, 8_500],\n",
    "    max_coordinate=[34_000, 11_500],\n",
    "    target_coordinate_system=\"global\",\n",
    ")\n",
    "sdata_xenium_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_images(elements=\"he_image\")\n",
    "        .pl.render_labels(elements=\"cell_labels\")\n",
    "        .pl.show(\n",
    "            title=\"Xenium cell segmentations\",\n",
    "            figsize=(12, 12),\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also modify the plotting call to just highlight where th(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_images(elements=\"he_image\")\n",
    "        .pl.render_labels(elements=\"cell_labels\")\n",
    "        .pl.show(\n",
    "            title=\"Xenium cell segmentations\",\n",
    "            figsize=(12, 12),\n",
    "        )\n",
    ")e segmentation masks are without obfuscating the H&E images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_images(elements=\"he_image\")\n",
    "        .pl.render_labels(\n",
    "            elements=\"cell_labels\",\n",
    "            fill_alpha=0,\n",
    "            outline_alpha=1,\n",
    "            contour_px=3,\n",
    "        ).pl.show(\n",
    "            title=\"Xenium cell segmentations\",\n",
    "            figsize=(12, 12),\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see several things:\n",
    "1) The underlaying histopathology image is fairly low in resolution and gets automatically upscaled to align with the segmentation masks.\n",
    "2) By far not every cell is succesfully segmented.\n",
    "3) The cell segmentation masks are colored with random colors - this is because the contained `AnnData` object doesn't annotate them. We can check this with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium_subset.tables[\"table\"].uns[\"spatialdata_attrs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the table annotates the `cell_circles` element. For Xenium, `spatialdata-io` automatically converts cell labels to circles. This is a performance improvement since Xenium slides can easily contain more than 500k cells. \n",
    "\n",
    "So, let's render these **Shapes** instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(7, 3))\n",
    "\n",
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_images(\"he_image\")\n",
    "        .pl.render_shapes(\"cell_circles\", color=\"transcript_counts\")\n",
    "        .pl.show(\n",
    "            title=\"transcript counts\",\n",
    "            ax=axs[0],\n",
    "        )\n",
    ")\n",
    "\n",
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_images(\"he_image\")\n",
    "        .pl.render_shapes(\"cell_circles\", color=\"cell_area\")\n",
    "        .pl.show(\n",
    "            title=\"cell area\",\n",
    "            ax=axs[1],\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this plot we can, for example, easily see that transcript count primarily correlates to cell area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #FF5C00; border-left-width: 15px; padding: 10px; background-color: #FFA500; color: black;\">\n",
    "    <strong>Note:</strong>\n",
    "    <p>In the following, we'll modify what the AnnData table annotated. This is slightly more complicated, but usually not neccecary. However, one can still benefit from knowing about this option.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium_subset.tables[\"table\"].obs[\"region\"] = \"cell_labels\"\n",
    "\n",
    "sdata_xenium_subset.set_table_annotates_spatialelement(\n",
    "    table_name=\"table\",\n",
    "    region=\"cell_labels\",\n",
    "    region_key=\"region\",\n",
    "    instance_key='cell_labels',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've adjusted this, we can also color the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_images(elements=\"he_image\")\n",
    "        .pl.render_labels(elements=\"cell_labels\", color=\"cell_area\")\n",
    "        .pl.show(\n",
    "            title=\"Xenium cell segmentations\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .pl.render_points()\n",
    "\n",
    "We can also directly visualize the transcript localisations that would otherwise we aggregated to a cell x gene matrix in Xenium. We'll use [`.pl.render_points()`](https://spatialdata.scverse.org/projects/plot/en/latest/plotting.html#spatialdata_plot.pl.basic.PlotAccessor.render_points) for that. For visual guidance, we'll overlay the cell segmentation masks.\n",
    "\n",
    "Due to the way the data is subset, one of the performance optimisations (the use of [`DataShader`](https://datashader.org/)) actually results in a weird visualization, so we'll disable it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_points(\n",
    "            method=\"matplotlib\", # We don't want an aggregated version but the raw points (-> no datashader)\n",
    "        )  \n",
    "        .pl.render_labels(\n",
    "            elements=\"cell_labels\",\n",
    "            fill_alpha=0,\n",
    "            outline_alpha=1,\n",
    "            contour_px=3,\n",
    "        ).pl.show(\n",
    "            title=\"Xenium points\",\n",
    "            figsize=(12, 12),\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the other function, [`.pl.render_points()`](https://spatialdata.scverse.org/projects/plot/en/latest/plotting.html#spatialdata_plot.pl.basic.PlotAccessor.render_points) gives us the option to color the points by certain covariates. Here, we're coloring by the fact whether a transcript was localized inside the nucleus mask or not. Of note is that this information isn't stored in the `AnnData` table, but `spatialdata-plot` automatically identifies the correct data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_points(\n",
    "            method=\"matplotlib\", # We don't want an aggregated version but the raw points (-> no datashader)\n",
    "            color=\"overlaps_nucleus\"\n",
    "        )  \n",
    "        .pl.render_labels(\n",
    "            elements=\"cell_labels\",\n",
    "            fill_alpha=0,\n",
    "            outline_alpha=1,\n",
    "            contour_px=3,\n",
    "        ).pl.show(\n",
    "            title=\"Xenium points\",\n",
    "            figsize=(12, 12),\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we're interested in specific genes, we can also only highlight those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_points(\n",
    "            method=\"matplotlib\", # We don't want an aggregated version but the raw points (-> no datashader)\n",
    "            color=\"feature_name\",\n",
    "            groups=[\"KRT7\", \"MLPH\", \"AGR3\"],\n",
    "            palette=[\"red\", \"green\", \"blue\"],\n",
    "            size=5,\n",
    "        )  \n",
    "        .pl.render_labels(\n",
    "            elements=\"cell_labels\",\n",
    "            fill_alpha=0,\n",
    "            outline_alpha=1,\n",
    "            contour_px=3,\n",
    "        ).pl.show(\n",
    "            title=\"Xenium points\",\n",
    "            figsize=(12, 12),\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's combine several things we learned to create a more complicated plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make custom cmap and norm\n",
    "cmap = matplotlib.cm.get_cmap(\"Reds\").copy()\n",
    "cmap.set_under((0.0, 0.0, 0.0, 0.0))\n",
    "norm = matplotlib.colors.Normalize(vmin=5, vmax=None)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(12, 4.5))\n",
    "\n",
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_points(\n",
    "            method=\"matplotlib\", # We don't want an aggregated version but the raw points (-> no datashader)\n",
    "            color=\"feature_name\",\n",
    "            groups=[\"KRT7\"],\n",
    "            palette=[\"red\"],\n",
    "            size=1,\n",
    "        )  \n",
    "        .pl.render_labels(\n",
    "            elements=\"cell_labels\",\n",
    "            fill_alpha=0,\n",
    "            outline_alpha=1,\n",
    "            contour_px=3,\n",
    "        ).pl.show(\n",
    "            title=\"KRT7 transcript localizations\",\n",
    "            ax=axs[0],\n",
    "        )\n",
    ")\n",
    "\n",
    "(\n",
    "    sdata_xenium_subset\n",
    "        .pl.render_images(\"he_image\")\n",
    "        .pl.render_labels(\n",
    "            elements=\"cell_labels\",\n",
    "            color=\"KRT7\",\n",
    "            fill_alpha=0.5,\n",
    "            outline_alpha=1,\n",
    "            cmap=\"Reds\",\n",
    "        ).pl.show(\n",
    "            title=\"Aggregated KRT7 counts\",\n",
    "            ax=axs[1],\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #4CAF50; border-left-width: 15px; padding: 10px; background-color: #F0FFF0; color: black;\">\n",
    "    <strong>Summary:</strong>\n",
    "    <p>This concludes the second part of our workshop. We've learned how to load and interact with different spatial technologies and how to perform basic plotting. In the next part, Anthony will guide us through a complete downstream analysis, including cell type clustering and integrating data from multiple experiments.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
