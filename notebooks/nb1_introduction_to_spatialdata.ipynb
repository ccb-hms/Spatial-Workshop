{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Introduction to SpatialData & Interactive Exploration\n",
    "\n",
    "**Instructor:** Tim Treis\n",
    "**Time:** 40 minutes\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the workshop! In this first notebook, we will introduce the core concepts behind the `SpatialData` framework.\n",
    "\n",
    "**Goals:**\n",
    "1. Understand the different components of a spatial dataset (Images, Labels, Shapes, Points).\n",
    "2. Learn how the `SpatialData` object acts as a unified container for these components.\n",
    "3. Gain hands-on experience exploring complex spatial data interactively with `napari`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a `SpatialData` object?\n",
    "\n",
    "Modern spatial omics experiments generate diverse types of data. For example, a single experiment might produce:\n",
    "\n",
    "*   A high-resolution histology image (**Image**).\n",
    "*   Segmentation masks defining where the cells are (**Labels**).\n",
    "*   Polygons outlining cell boundaries (**Shapes**).\n",
    "*   The locations of individual RNA molecules (**Points**).\n",
    "*   A table of gene counts per cell (**Table**).\n",
    "\n",
    "The `SpatialData` framework, part of the `scverse` ecosystem, provides a single, standardized object to hold all these different *elements* together in a coordinated way.\n",
    "\n",
    "<img src=\"../resources/elements.png\" alt=\"spatialdata design is modular\" style=\"max-width: 800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our First Dataset: A Xenium Example\n",
    "\n",
    "To begin, we will load a pre-processed dataset into a `SpatialData` object. For this workshop, we will be working with the `.zarr` format, which is a modern, high-performance storage format ideal for large scientific data.\n",
    "\n",
    "Our first dataset is a `Xenium` experiment, which is a great example because it contains all the different types of spatial elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cleaner output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata as sd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to our data directory\n",
    "# Note: This path is relative to the repository's root directory\n",
    "_DATA_DIR_PATH = Path(\"../data/\")\n",
    "_XENIUM_PATH = _DATA_DIR_PATH / \"xenium_lung_cancer_subset.zarr\"\n",
    "_MERFISH_PATH = _DATA_DIR_PATH / \"merfish_subset.zarr\"\n",
    "\n",
    "print(f\"Loading data from '{_XENIUM_PATH}'\")\n",
    "\n",
    "# Load the pre-processed Xenium dataset\n",
    "sdata_xenium = sd.read_zarr(_XENIUM_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the `SpatialData` object we just created. We can directly access the contained images by their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the contained **Images** are represented as a [`xarray.DataTree`](https://docs.xarray.dev/en/latest/generated/xarray.DataTree.html) which we use for **multiscale images**. These are image pyramids that store the same image at different resolutions, which is key for fast visualization of very large images.\n",
    "\n",
    "![image pyramid](../resources/image_pyramid.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium.images[\"morphology_focus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also directly access and plot the data contained\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(sdata_xenium.images[\"morphology_focus\"][\"scale4\"].image.transpose(\"y\", \"x\", \"c\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, segmentation masks (**Labels**) are also represented as images and can be accessed the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sdata_xenium.labels[\"nucleus_labels\"][\"scale4\"].image.transpose(\"y\", \"x\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points\n",
    "\n",
    "The **Points** objects are represented as a [`Dask.DataFrame`](https://docs.dask.org/en/stable/dataframe.html) which allows us to lazily load the points, meaning that not all of them will be loaded into memory immedediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium.points[\"transcripts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can load them on-demand though.\n",
    "\n",
    "sdata_xenium.points[\"transcripts\"].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmentation masks (**Shapes**) are stored as [`geopandas.GeoDataFrame`](https://geopandas.org/en/v1.1.0/docs/reference/api/geopandas.GeoDataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium.shapes[\"cell_boundaries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium.shapes[\"cell_boundaries\"].geometry[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables\n",
    "\n",
    "Lastly, tabular data, for example, the table of gene counts, is stored as an [`anndata.AnnData`](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.html) object that many of you may be familiar with from single-cell analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_xenium.tables[\"table\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Exploration with `napari`\n",
    "\n",
    "While printing the object summary is useful, the best way to understand spatial data is to *see* it. We use **Napari**, a fast, interactive, multi-dimensional image viewer, to explore our `SpatialData` objects.\n",
    "\n",
    "The `napari-spatialdata` plugin provides the bridge between our data and the viewer. To demonstrate its features, we'll load a `MERFISH` dataset, another high-resolution imaging-based technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_merfish = sd.read_zarr(_MERFISH_PATH)\n",
    "sdata_merfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn: Launching Napari\n",
    "\n",
    "Now, let's launch the interactive viewer. \n",
    "\n",
    "**Instructions:**\n",
    "1. Uncomment and run the code cell below.\n",
    "2. A new window for Napari should appear. This may take a few seconds.\n",
    "3. Follow along as we tour the interface and explore the data layers.\n",
    "\n",
    "**Troubleshooting**\n",
    "`napari` support within Docker containers is limited. If you are not able to run the notebook with the current Docker configuration, please skip the cell below and follow the demo from the instructor. To run `napari` locally without Docker, please use `mamba`, as explained in [the section \"Using conda / mamba\" from this guide](https://github.com/PMBio/spatialdata-workshops/tree/main?tab=readme-ov-file#using-conda--mamba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from napari_spatialdata import Interactive\n",
    "\n",
    "# run napari\n",
    "Interactive(sdata_merfish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #4CAF50; border-left-width: 15px; padding: 10px; background-color: #F0FFF0; color: black;\">\n",
    "    <strong>Tip:</strong>\n",
    "    <p>You can also view a .zarr file from your terminal with:<br><code>python -m napari_spatialdata view ../data/merfish_subset.zarr</code>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tour of the `napari-spatialdata` Interface\n",
    "\n",
    "The Napari window is composed of several key parts. The `napari-spatialdata` plugin adds the panels highlighted in green.\n",
    "\n",
    "![overview of the napari-spatialdata interface](../resources/napari_spatialdata0.jpg)\n",
    "\n",
    "**Key areas to know:**\n",
    "- **Layers list (bottom-left):** This is where you can see all the data layers (images, shapes, points) and toggle their visibility, change their order, or adjust their opacity.\n",
    "- **`spatialdata` viewer (top-right):** This shows you which coordinate systems are available and lets you select elements to view.\n",
    "- **`spatialdata` table annotation (bottom-right):** This powerful panel lets you color your spatial elements (like cells) by any value in the associated `AnnData` table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of adding elements to the viewer and interacting with them.\n",
    "\n",
    "![adding elements](../resources/napari_spatialdata1.gif)\n",
    "![interaction with napari](../resources/napari_spatialdata2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real power comes from coloring your spatial elements by their associated data. Here, we color cells by different annotations stored in the `AnnData` table, including categorical variables (`region`) and continuous variables (gene expression).\n",
    "\n",
    "![showing annotations](../resources/napari_spatialdata3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The various selectors on the right side of the interface reflect the structure of the `AnnData` object that annotates our spatial elements. The dropdown menus map directly to the `.obs`, `.layers`, and `.obsm` slots of the table.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/scverse/anndata/main/docs/_static/img/anndata_schema.svg\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Tip: Coloring Points by their Own Attributes\n",
    "\n",
    "Most of the time, you will color cells/spots by data in an `AnnData` table. However, it's also possible to color `Points` or `Shapes` by columns in their own internal dataframe. For example, individual transcripts might have a `quality_value` column.\n",
    "\n",
    "The \"Dataframe columns\" list widget at the bottom of the annotation panel allows you to do this.\n",
    "\n",
    "![showing annotations points](../resources/napari_spatialdata4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 1px solid #4CAF50; border-left-width: 15px; padding: 10px; background-color: #F0FFF0; color: black;\">\n",
    "    <strong>Summary:</strong>\n",
    "    <p>This concludes our introduction to the <code>SpatialData</code> object and interactive visualization. In the next notebook, we'll learn how to create static, publication-ready plots using <a href=\"https://spatialdata.scverse.org/projects/plot/en/latest/\"><code>spatialdata-plot</code></a>.</p>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spatial Workshop (HMS)",
   "language": "python",
   "name": "spatial-workshop"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
